{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mjm/catkin_workspaces/baxter_ws/src/aml/aml_robot/src/aml_dl\n"
     ]
    }
   ],
   "source": [
    "aml_dl_path = os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), '..', ''))\n",
    "print aml_dl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(aml_dl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named nets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0fa147e991d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcnn_pose_estimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mjm/catkin_workspaces/baxter_ws/src/aml/aml_robot/src/aml_dl/cnn_pose_estimation/model/tf_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# sys.path.append(tf_slim_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minception_preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mslim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named nets"
     ]
    }
   ],
   "source": [
    "import cnn_pose_estimation.model.tf_model as tf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 50\n",
    "IMAGE_HEIGHT = 50\n",
    "IMAGE_CHANNELS = 3\n",
    "NUM_FP = 4\n",
    "\n",
    "network_params = {\n",
    "    'num_filters': [5, 5,NUM_FP],\n",
    "    'batch_size': 25,\n",
    "    'image_width': IMAGE_WIDTH,\n",
    "    'image_height': IMAGE_HEIGHT,\n",
    "    'image_channels': IMAGE_CHANNELS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('foo20', reuse=False):\n",
    "    #tf.get_variable_scope().reuse_variables()\n",
    "    nn = tf_model.pose_estimation_network(dim_input=IMAGE_WIDTH*IMAGE_HEIGHT*IMAGE_CHANNELS, network_config=network_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[  2.09471636e-07,  -5.51639801e-08,   6.88168242e-08]], dtype=float32), 0.059999991]\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "image = np.random.randn(IMAGE_HEIGHT,IMAGE_WIDTH,3)\n",
    "image = np.transpose(image,(2,1,0)) # If the image is WxHxC, make it CxWxH\n",
    "image = image.flatten()\n",
    "\n",
    "fc_op = nn['fc_out']\n",
    "loss_op = nn['loss']\n",
    "input_tensor = nn['input']\n",
    "position = nn['position']\n",
    "print sess.run([fc_op,loss_op], feed_dict={input_tensor: np.expand_dims(image,axis=0),\n",
    "                                 position: np.expand_dims(np.ones(3),axis=0)\n",
    "                                })\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
